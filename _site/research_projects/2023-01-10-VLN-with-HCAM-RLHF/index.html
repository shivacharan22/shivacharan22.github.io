<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v9.1.6 <https://hydejack.com/>
-->







<head>
  




  <meta name="robots" content="noindex">



  
    
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback | shivacharan oruganti</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback" />
<meta name="author" content="shivacharan oruganti" />
<meta property="og:locale" content="en" />
<meta name="description" content="Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback" />
<meta property="og:description" content="Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback" />
<link rel="canonical" href="http://localhost:4000/research_projects/2023-01-10-VLN-with-HCAM-RLHF/" />
<meta property="og:url" content="http://localhost:4000/research_projects/2023-01-10-VLN-with-HCAM-RLHF/" />
<meta property="og:site_name" content="shivacharan oruganti" />
<meta property="og:image" content="http://localhost:4000/assets/img/model.jpeg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-01-10T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/assets/img/model.jpeg" />
<meta property="twitter:title" content="Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"shivacharan oruganti"},"dateModified":"2023-09-09T18:06:07-04:00","datePublished":"2023-01-10T00:00:00-05:00","description":"Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback","headline":"Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback","image":"http://localhost:4000/assets/img/model.jpeg","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/research_projects/2023-01-10-VLN-with-HCAM-RLHF/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/IMG_8880.jpg"},"name":"shivacharan oruganti"},"url":"http://localhost:4000/research_projects/2023-01-10-VLN-with-HCAM-RLHF/"}</script>
<!-- End Jekyll SEO tag -->


  

  



  <meta name="theme-color" content="rgb(3,29,52)">


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">

<meta name="mobile-web-app-capable" content="yes">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="shivacharan oruganti">
<meta name="apple-mobile-web-app-status-bar-style" content="default">

<meta name="application-name" content="shivacharan oruganti">

<meta name="generator" content="Hydejack v9.1.6" />


<link rel="alternate" href="http://localhost:4000/research_projects/2023-01-10-VLN-with-HCAM-RLHF/" hreflang="en">

<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="shivacharan oruganti" />


<link rel="shortcut icon"    href="/assets/icons/favicon.ico">
<link rel="apple-touch-icon" href="/assets/icons/icon-192x192.png">

<link rel="manifest" href="/assets/site.webmanifest">

<link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com">



<link rel="preload" href="/assets/img/swipe.svg" as="image" id="_hrefSwipeSVG">






<script>!function(r,c){"use strict";function a(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}r.loadJS=function(e,t){var n=c.createElement("script"),e=(n.src=e,t&&a(n,"load",t,{once:!0}),c.scripts[0]);return e.parentNode.insertBefore(n,e),n},r._loaded=!1,r.loadJSDeferred=function(e,t){var n=c.createElement("script");function o(){r._loaded=!0,t&&a(n,"load",t,{once:!0});var e=c.scripts[0];e.parentNode.insertBefore(n,e)}return n.src=e,r._loaded?o():a(r,"load",o,{once:!0}),n},r.setRel=r.setRelStylesheet=function(e){a(c.getElementById(e),"load",function(){this.rel="stylesheet"},{once:!0})}}(window,document);
!function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this);
!function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this);
!function(w) {
  w._baseURL = '/';
  w._publicPath = '/assets/js/';
  w._noPushState = false;
  w._noDrawer = false;
  w._noNavbar = false;
  w._noToc = false;
  w._noSearch = false;
  w._search = {
    DATA_URL: '/assets/sitedata.json?no-cache',
    STORAGE_KEY: 'mini-search/',
    INDEX_KEY: 'index--2023-09-09T20:50:21-04:00',
  };
  w._clapButton = true;
}(window);</script>


<script async src="/assets/bower_components/MathJax/es5/tex-mml-chtml.js" id="_MathJax"></script>


<!--[if gt IE 8]><!---->

  




<link rel="stylesheet" href="/assets/css/hydejack-9.1.6.css" id="_stylePreload">
<link rel="stylesheet" href="/assets/icomoon/style.css" id="_iconsPreload">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700%7CNoto+Sans:400,400i,700,700i&display=swap" id="_fontsPreload">



  <style id="_pageStyle">

html{--accent-color: rgb(3,29,52);--accent-color-faded: rgba(3, 29, 52, 0.5);--accent-color-highlight: rgba(3, 29, 52, 0.1);--accent-color-darkened: #010910;--theme-color: rgb(3,29,52)}
</style>


<!--<![endif]-->




</head>

<body class="no-break-layout">
  


<hy-push-state
  id="_pushState"
  replace-selector="#_main"
  link-selector="a[href]:not([href^='/assets/']):not(.external):not(.no-push-state)"
  script-selector="script"
  duration="500"
  hashchange
>
  
  
  <div id="_navbar" class="navbar fixed-top">
  <div class="content">
    <span class="sr-only">Jump to:</span>
    <div class="nav-btn-bar">
      <a id="_menu" class="nav-btn no-hover" href="#_drawer--opened">
        <span class="sr-only">Navigation</span>
        <span class="icon-menu"></span>
      </a>
      <div class="nav-span"></div>
    </div>
  </div>
</div>
<hr class="sr-only" hidden />

  <main
  id="_main"
  class="content layout-post"
  role="main"
>
  <nav id="breadcrumbs" class="screen-only"><ul>
  
  
    <li><a href="/">home</a></li>
    
      <li>
        
          <span>/</span>
          
          
          <a href="/research_projects/">research_projects</a>
        
      </li>
    
      <li>
        
          <span>/</span>
          <span>2023-01-10-VLN-with-HCAM-RLHF</span>
        
      </li>
    
  
</ul></nav>
  










<article id="post-research_projects-VLN-with-HCAM-RLHF" class="page post mb6" role="article">
  <header>
    <h1 class="post-title flip-project-title">
      
        Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback
      
    </h1>

    <div class="post-date">
      
      <span class="ellipsis mr1">
        <time datetime="2023-01-10T00:00:00-05:00">10 Jan 2023</time> in <span>Research_projects</span> 
      </span>
      
        
          
          
          
            
            
            <span class="ellipsis" data-tippy-content="Last modified at: 09 Sep 2023">
              <span class="sr-only">Last modified at:</span>
              <span class="icon-history"></span>
              <time datetime="2023-09-09T18:06:07-04:00">2023-09-09</time>
            </span>
          
        
      
    </div>

    
    
      
        <div class="img-wrapper lead aspect-ratio sixteen-nine flip-project-img">
          


<img
  
    src="/assets/img/model.jpeg"
    
    
  
  alt="Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback"
  
  
  width="864"
  height="486"
  loading="lazy"
/>

        </div>
      
      
    

    



  
    <p class="note-sm" >
      Vision Language Navigation Using Hierarchical Chunk Memory Attention and Reinforcement Learning with Human Feedback

    </p>
  


  </header>

  
    <hr />

<h2 id="results-go-to-github-and-run-the-below-commandfor-ui">Results go to <a href="https://github.com/shivacharan22/VLN-Using-Hierarchical-Chunk-Memory-Attention-and-RLHF">github</a> and run the below command(for UI)</h2>
<blockquote>
  <p>streamlit run app.py</p>
</blockquote>

<h2 id="problem-and-summary-of-the-project">Problem and summary of the project</h2>

<p>Vision language navigation is a task in Embodied AI research where an agent has to navigate to a location mentioned given language instruction and visual inputs. However, the vision language navigation task poses some challenges, like Visual Complexity, Language Ambiguity, Multimodal Integration, Generalization to Unseen Environments, Dealing with Uncertainty, Zero-shot Learning, Real-time Decision-making, Evaluation Metrics, Human- Agent Interaction, and Long-Term Dependencies. In this project, we concentrate on Human- Agent Interaction and Long-Term Dependencies Challenges for which we introduce HCAM and RLHF mechanisms to our model and training, which enable the agent to think like a human while navigating and storing to infer to make future informed decisions in the same episode as cross episode memory is not tested in this project. We use the Mattersim simulator for an environment with 1.2 TB of data. The dataset comprises 194,400 RGB-D images of 90 building-scale scenes with 21,567 navigation instructions. Our model will be trained using contrastive supervised learning with ground actions, and RLHF techniques will be used as mentioned below. We observe its success in Human-Agent Interaction and Long-Term dependencies and failure in Generalization to Unseen Environments. The metrics used are success rate 42%, Trajectory length - x, and Navigation error - Y.</p>

<h2 id="intution">Intution</h2>

<p><img src="/assets/img/arvl.jpeg" alt="The layout of the whole network" /></p>

<h3 id="why-hcam">why HCAM</h3>

<p>Regarding Long-Term Dependencies, VLN tasks often require agents to remember and refer to previous states, actions, or instructions to make informed navigation choices. Capturing and utilizing long-term dependencies effectively is a challenge, particularly when memory and context span over extended periods. HCAM introduced by can be experimented upon in this case. The original paper presents a novel approach called “hierarchical memory” HCAM to enhance the decision-making capabilities of RL agents. To evaluate the effectiveness of hierarchical memory, the authors conduct experiments, including Remembering the Ballet, which involves the agent recalling its previous observations and going to that particular dancer after seeing a 12-32 dance episode. Memory and recall were tested in all of these experiments. The results demonstrate that agents equipped with hierarchical memory outperform those without memory or with a single-level memory.
Furthermore, the hierarchical memory allows the agents to generalize their knowledge across different tasks and adapt their decision-making strategies to unseen situations. Overall, the paper presents the concept of hierarchical memory as a valuable mechanism for RL agents to improve their decision-making abilities. By enabling agents to perform mental time travel and leverage past experiences, the hierarchical memory enhances the agents’ ability to generalize, adapt, and make informed decisions in dynamic environments. We will be using this mechanism in this paper.</p>

<p><img src="/assets/img/Hcam.png" alt="HCAM" /></p>

<h3 id="why-rlhf">why RLHF</h3>

<p>The next part of this paper uses RLHF. The concept of Reinforcement Learning with Human Feedback (RLHF) has been explored in various studies, but pinpointing the exact first paper on RLHF can be challenging due to the vast literature in the field. However, one influential early article on RLHF is “Apprenticeship Learning via Inverse Reinforcement Learning” by Pieter Abbeel and Andrew Y. Ng. In this paper, the authors introduce the concept of apprenticeship learning, which combines ideas from inverse reinforcement learning (IRL) and RLHF. The focus is on learning from demonstrations provided by an expert rather than relying solely on trial-and-error exploration. By incorporating human demonstrations, the RL agent can learn from an expert’s behavior and acquire skills more efficiently. The paper proposes a mathematical framework for apprenticeship learning, which involves estimating the underlying reward function from expert demonstrations and then using this estimated reward function to train the RL agent.
RLHF was initially introduced as an approach to address the challenges of sparse reward signals and accelerate the learning progress in RL. Traditional RL methods rely on trial-and- error exploration to learn optimal policies, which can be time-consuming and inefficient. RLHF leverages human expertise to provide additional guidance and feedback to the RL agent, helping it learn faster and perform better. In RLHF, human feedback can take various forms, such as demonstrations, preferences, or direct evaluations. Demonstrations involve a human expert showcasing desired behaviors or providing example trajectories for the RL agent to learn from. Preferences involve the comparison of different actions or trajectories to indicate preferred choices. Direct evaluations provide explicit feedback or reward signals to guide the learning process. For example, we generate multiple trajectories, manually compare them in two pairs, and select the most successful one.</p>

<p><img src="/assets/img/Blank diagram (4).png" alt="Step-2" /></p>

<p>An additional step-2 was to run with contrastive learning on the whole network with simulated game plays with langauge and image pairs as shown above.</p>

<h2 id="successful-navigation-sample">successful navigation sample:</h2>
<p>https://github.com/shivacharan22/shivacharan22.github.io/assets/54499416/5c2073a6-a176-4f40-8d33-e9abcbf1e5f2</p>

<h2 id="unsuccessful-navigation-sample">Unsuccessful navigation sample:</h2>
<p>https://github.com/shivacharan22/VLN-Using-Hierarchical-Chunk-Memory-Attention-and-RLHF/blob/main/videos/val_v2.mp4</p>

<h2 id="for-detailed-information-please-check-out-this-report">For detailed information please check out this <a href="https://github.com/shivacharan22/shivacharan22.github.io/files/12554322/Capstone_report_upload_.pdf">!Report!</a></h2>

<h2 id="appendix">Appendix:</h2>

<h3 id="setup-i-used-to-run">Setup I used to run:</h3>

<p>I used GCP VM with 104 gb RAM with A100 GPU and 32 CPUs with Ubantu18.05 OS.</p>

<p>Below are the commands if you wanna fasten your process:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-keyring_1.0-1_all.deb:

#This command uses wget to download a Debian package (cuda-keyring) from an NVIDIA repository. The package is used to authenticate CUDA-related software.
sudo dpkg -i cuda-keyring_1.0-1_all.deb:

#This command installs the previously downloaded Debian package (cuda-keyring) using dpkg. This package likely contains GPG keys and other authentication-related data for NVIDIA's CUDA repository.
sudo apt-get update:

#This command updates the package lists for the APT package manager, ensuring that you have the latest information about available packages and their versions.
sudo apt-get -y install cuda:

#This command installs CUDA, which is a parallel computing platform and application programming interface (API) developed by NVIDIA. CUDA is commonly used for GPU-accelerated computations.
sudo apt update:

#This command updates the package lists again.
sudo apt install apt-transport-https ca-certificates curl software-properties-common:

#This command installs various utilities and libraries necessary for handling HTTPS, certificates, and adding software repositories.
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -:

#This command fetches the Docker GPG key and adds it to the list of trusted keys on your system. It's used to verify the authenticity of Docker packages.
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable":

#This command adds the official Docker repository to your system's list of software sources.
sudo apt update:

#This command updates the package lists again to include the Docker repository.
sudo apt-cache policy docker-ce:

#This command checks the available versions of Docker in the newly added repository.
sudo apt install docker-ce:

#This command installs Docker Community Edition (CE), a containerization platform.
sudo systemctl status docker:

#This command checks the status of the Docker service, confirming that it is running.
sudo usermod -aG docker ${USER}:

#This command adds your user account to the "docker" group, allowing you to run Docker commands without using "sudo."
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -:

#This command fetches the NVIDIA Docker GPG key and adds it to your system's trusted keys.
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list:

#This command adds the NVIDIA Docker repository to your system's list of software sources.
sudo apt-get update:

#This command updates the package lists once more to include the NVIDIA Docker repository.
sudo apt-get install -y nvidia-docker2:

#This command installs NVIDIA Docker 2, which enables you to use NVIDIA GPUs with Docker containers.
sudo pkill -SIGHUP dockerd:

#This command sends a signal to the Docker daemon (dockerd) to reload its configuration. This is often necessary after installing Docker-related software.
xhost +:

#This command allows any user to connect to your X server (GUI) temporarily.
nvidia-docker run -it -e DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix --mount type=bind,source=$MATTERPORT_DATA_DIR,target=/root/mount/Matterport3DSimulator/data/v1/scans,readonly --volume pwd:/root/mount/Matterport3DSimulator mattersim:9.2-devel-ubuntu18.04:

#This is a complex command that appears to run a Docker container named "mattersim:9.2-devel-ubuntu18.04." The container is configured to use NVIDIA Docker, share the X server display, and mount specific directories as volumes.
cd /root/mount/Matterport3DSimulator:

#This command changes the current directory to "/root/mount/Matterport3DSimulator."
git clone --recursive https://github.com/peteanderson80/Matterport3DSimulator.git:

#This command clones a Git repository named "Matterport3DSimulator" and its submodules from the specified URL.
</code></pre></div></div>

  
</article>



  <hr class="dingbat related mb6" />






  
     


  <aside class="about related mt4 mb4" role="complementary">
    
    

<div class="author mt4">
  

  
    


<img
  
    src="/assets/img/IMG_8880.jpg"
    
    
  
  alt="shivacharan oruganti"
  class="avatar"
  
  width="120"
  height="120"
  loading="lazy"
/>

  

  
  
  <h2  class="page-title hr-bottom">
    About
  </h2>

  <p>I am currently pursuing my Master’s degree in Artificial Intelligence at Boston University, where I am delving deep into the intricate world of AI research and development. My academic journey began with an undergraduate degree in Computer Science and Engineering from VIT,vellore. I am curious about playing with reinforcement learning concepts and multi-model AI, especially when applied to the dynamic and ever-evolving landscape of trading markets. I have experience in making RL agents for Vision Language tasks like navigation and interaction, SDN network protection in my projects and privacy decision-making for companies’ products as an AI research intern at Chipsil Tech. Also, have experience in making Deep learning and machine learning models in various competitions and projects including making a state-of-the-art hybrid DL model on the Stanford University mosquito wingbeat dataset,showcasing my commitment to pushing the boundaries of what’s possible in the field. I am driven by the desire to translate cutting-edge research findings into actionable insights and strategies that can navigate the complexities of financial markets. My relentless drive for innovation has led me to explore the intersection of AI and trading bots. If you have ideas or are interested in collaborating on implementing RL strategies for trading, I’m always eager to connect and discuss the possibilities. Let’s engage in a conversation that can potentially shape the future of AI in finance.</p>


  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://twitter.com/shivaco22" title="Twitter" class="no-mark-external">
      <span class="icon-twitter"></span>
      <span class="sr-only">Twitter</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/shivacharan22" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:shivaco@bu.edu" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://instagram.com/shivacharano" title="Instagram" class="no-mark-external">
      <span class="icon-instagram"></span>
      <span class="sr-only">Instagram</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.linkedin.com/in/<firstname-lastname-string>" title="LinkedIn" class="no-mark-external">
      <span class="icon-linkedin2"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>

  </aside>


  

  
  

  
    


  <aside class="related mb4" role="complementary">  <h2 class="hr-bottom">Related Posts</h2>  <ul class="related-posts">                  <li class="h4">  <a href="/research_projects/2022-08-01-HYD_NN/" class="flip-title"><span>A Hybrid Network Combining Cnn and Transformer Encoder to Classify Mosquitoes Based on Wing Beat Frequencies</span></a>  <time class="faded fine" datetime="2022-08-01T00:00:00-04:00">01 Aug 2022</time></li>                        <li class="h4">  <a href="/research_projects/2022-07-11-learning-embedding/" class="flip-title"><span>Learning-Embedding-for-images-using-Deep-leaning</span></a>  <time class="faded fine" datetime="2022-07-11T00:00:00-04:00">11 Jul 2022</time></li>                        <li class="h4">  <a href="/research_projects/2021-06-23-Realized-Volatility/" class="flip-title"><span>Volatility-prediction</span></a>  <time class="faded fine" datetime="2021-06-23T00:00:00-04:00">23 Jun 2021</time></li>            </ul></aside>

  

  
  

  
    

  


  
<footer class="content" role="contentinfo">
  <hr/>
  
    <p><small class="copyright">© 2021. All rights reserved.
</small></p>
  
  
    <p><small>Powered by <a class="external" href="https://hydejack.com/">Hydejack</a> v<span id="_version">9.1.6</span></small></p>
  <hr class="sr-only"/>
</footer>


</main>

  <hy-drawer
  id="_drawer"
  class=""
  side="left"
  threshold="10"
  noscroll
  
>
  <header id="_sidebar" class="sidebar" role="banner">
    




<div class="sidebar-bg sidebar-overlay" style="background-color:rgb(3,29,52);background-image:url(/assets/img/bgi.jpeg)"></div>

    <div class="sidebar-sticky">
  <div class="sidebar-about">
    
      <a class="no-hover" href="/" tabindex="-1">
        <img src="/assets/img/IMG_8880.jpg" class="avatar" alt="shivacharan oruganti" width="120" height="120" loading="lazy" />
      </a>
    
    <a class="sidebar-title" href="/"><h2 class="h1">shivacharan oruganti</h2></a>
    
    
      <p class="">
        #AI Grad Student #boston_university

      </p>
    
  </div>

  <nav class="sidebar-nav heading" role="navigation">
    <span class="sr-only">Navigation:</span>
<ul>
  
    
      
      <li>
        <a
          id="_drawer--opened"
          href="/"
          class="sidebar-nav-item "
          
        >
          Research-projects
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/about/"
          class="sidebar-nav-item "
          
        >
          About
        </a>
      </li>
    
  
</ul>

  </nav>

  
  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://twitter.com/shivaco22" title="Twitter" class="no-mark-external">
      <span class="icon-twitter"></span>
      <span class="sr-only">Twitter</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/shivacharan22" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:shivaco@bu.edu" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://instagram.com/shivacharano" title="Instagram" class="no-mark-external">
      <span class="icon-instagram"></span>
      <span class="sr-only">Instagram</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.linkedin.com/in/<firstname-lastname-string>" title="LinkedIn" class="no-mark-external">
      <span class="icon-linkedin2"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>
  </header>
</hy-drawer>
<hr class="sr-only" hidden />

</hy-push-state>


  <!--[if gt IE 10]><!---->
  <script nomodule>!function(){var t,n=document.createElement("script");!("noModule"in n)&&"onbeforeload"in n&&(t=!1,document.addEventListener("beforeload",function(e){if(e.target===n)t=!0;else if(!e.target.hasAttribute("nomodule")||!t)return;e.preventDefault()},!0),n.type="module",n.src=".",document.head.appendChild(n),n.remove())}();
</script>
  <script src="/assets/js/hydejack-9.1.6.js" type="module"></script>
  <script src="/assets/js/LEGACY-hydejack-9.1.6.js" nomodule defer></script>
  

  

<!--<![endif]-->
  <!-- <script>
  document.querySelector('hy-push-state').setAttribute('prefetch', '');

  document.querySelectorAll('.sidebar a[href^="/"]').forEach(function (el) { 
    el.addEventListener('click', function (e) {
      if (el.pathname === window.location.pathname) {
        e.preventDefault();
        e.stopPropagation();
        document.querySelector('hy-drawer').close();
      }
    });
  });
</script> -->

<!--
Code for integrating CloudFlare's email protection with Hydejack's single page app loading.
-->
<script>
  document.getElementById('_pushState').addEventListener('hy-push-state-after', function (e) {
    function e(e){
      (console.error?console.error:console.log).call(console,e)
    }

    function t(e){
      return l.innerHTML='<a href="'+e.replace(/"/g,"&quot;")+'"></a>',l.childNodes[0].getAttribute("href")
    }

    function r(e,t){
      var r=e.substr(t,2);return parseInt(r,16)
    }

    function n(e,n){
      for(var o="",c=r(e,n),a=n+2;a<e.length;a+=2){
        var l=r(e,a)^c;
        o+=String.fromCharCode(l)
      }
      return t(o)
    }

    var o="/cdn-cgi/l/email-protection#",
        c=".__cf_email__",
        a="data-cfemail",
        l=document.createElement("div");

    !function(){
      for(var t=document.getElementsByTagName("a"),r=0;r<t.length;r++)
        try{
          var c=t[r],a=c.href.indexOf(o);
          a>-1&&(c.href="mailto:"+n(c.href,a+o.length))
        }catch(t){
          e(t)
        }
    }(),
    function(){
      for(var t=document.querySelectorAll(c),r=0;r<t.length;r++)
        try{
          var o=t[r],l=n(o.getAttribute(a),0),i=document.createTextNode(l);
          o.parentNode.replaceChild(i,o)
        }catch(t){
          e(t)
        }
    }()
  });
</script>





<div hidden>
  
  <h2 class="sr-only">Templates (for web app):</h2>

  <template id="_animation-template">
  <div class="animation-main fixed-top">
    <nav id="breadcrumbs" class="screen-only"><ul>
  
  
</ul></nav>
    <div class="content">
      <div class="page"></div>
    </div>
  </div>
</template>

  <template id="_loading-template">
  <div class="loading nav-btn fr">
    <span class="sr-only">Loading…</span>
    <span class="icon-cog"></span>
  </div>
</template>

  <template id="_error-template">
  <div class="page">
    <h1 class="page-title">Error</h1>
    
    
    <p class="lead">
      Sorry, an error occurred while loading <a class="this-link" href=""></a>.

    </p>
  </div>
</template>

  <template id="_permalink-template">
  <a href="#" class="permalink">
    <span class="sr-only">Permalink</span>
    <span class="content-hash"></span>
  </a>
</template>

</div>


</body>
</html>
